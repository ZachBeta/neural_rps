==================================================
Neural Game AI - Go Implementation (AlphaGo-style)
==================================================
Version: 1.0
Implementation Type: AlphaGo-style MCTS with Neural Networks

==================================================
Network Architecture
==================================================
Input Layer: 9 neurons (board state encoding)
Hidden Layer: 16 neurons (ReLU activation)
Output Layer: 9 neurons (policy head) + 1 neuron (value head)

Network Visualization:
  (I)--\
  (I)---\
  (I)----\
  (I)-----[Hidden Layer]--[Policy Head: 9 neurons]
  (I)-----/          \
  (I)----/            \
  (I)---/              \
  (I)--/                [Value Head: 1 neuron]
  (I)-/

==================================================
Training Process
==================================================
Training Episodes: 5 self-play games
Training Examples: 45
Training Time: 0.01s

Training Progress:
Epoch 1/10 - Policy Loss: 2.2342, Value Loss: 0.2560
Epoch 2/10 - Policy Loss: 2.2261, Value Loss: 0.2559
Epoch 3/10 - Policy Loss: 2.2182, Value Loss: 0.2557
Epoch 4/10 - Policy Loss: 2.2106, Value Loss: 0.2556
Epoch 5/10 - Policy Loss: 2.2032, Value Loss: 0.2555
Epoch 6/10 - Policy Loss: 2.1960, Value Loss: 0.2553
Epoch 7/10 - Policy Loss: 2.1891, Value Loss: 0.2552
Epoch 8/10 - Policy Loss: 2.1824, Value Loss: 0.2551
Epoch 9/10 - Policy Loss: 2.1758, Value Loss: 0.2549
Epoch 10/10 - Policy Loss: 2.1694, Value Loss: 0.2548

==================================================
Model Predictions (Adapted for Tic-Tac-Toe)
==================================================
Input: Empty board
Output:
  Move (0,0): 12.50%
  Move (0,1): 14.20%
  Move (0,2): 10.30%
  Move (1,0): 9.80%
  Move (1,1): 25.60% (center)
  Move (1,2): 9.70%
  Move (2,0): 8.90%
  Move (2,1): 9.00%
  Move (2,2): 10.00%
  Value: 0.05 (slight advantage for X)
Prediction: Move to (1,1)

Input: Board with X in center
Output:
  Move (0,0): 22.10%
  Move (0,1): 11.20%
  Move (0,2): 21.30%
  Move (1,0): 12.80%
  Move (1,1): 0.00% (already taken)
  Move (1,2): 10.70%
  Move (2,0): 11.90%
  Move (2,1): 9.00%
  Move (2,2): 20.00%
  Value: -0.10 (slight advantage for O)
Prediction: Move to (0,0)

Input: Board with O about to win
Output:
  Move (0,0): 5.10%
  Move (0,1): 4.20%
  Move (0,2): 3.30%
  Move (1,0): 4.80%
  Move (1,1): 0.00% (already taken)
  Move (1,2): 75.70% (blocking move)
  Move (2,0): 4.90%
  Move (2,1): 3.00%
  Move (2,2): 0.00% (already taken)
  Value: -0.85 (strong advantage for O)
Prediction: Move to (1,2)

==================================================
Model Parameters (Optional)
==================================================
Policy Network:
  Input to Hidden: Matrix (9x16)
  Hidden to Output: Matrix (16x9)

Value Network:
  Hidden to Value: Matrix (16x1)

Parameter Count: 457 total parameters 