// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
// versions:
// - protoc-gen-go-grpc v1.3.0
// - protoc             v5.29.3
// source: proto/neural_service.proto

package proto

import (
	context "context"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
)

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
// Requires gRPC-Go v1.32.0 or later.
const _ = grpc.SupportPackageIsVersion7

const (
	NeuralService_Predict_FullMethodName      = "/neural.NeuralService/Predict"
	NeuralService_BatchPredict_FullMethodName = "/neural.NeuralService/BatchPredict"
	NeuralService_GetModelInfo_FullMethodName = "/neural.NeuralService/GetModelInfo"
)

// NeuralServiceClient is the client API for NeuralService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type NeuralServiceClient interface {
	// Predict runs model inference on a single input
	Predict(ctx context.Context, in *PredictRequest, opts ...grpc.CallOption) (*PredictResponse, error)
	// BatchPredict runs model inference on multiple inputs simultaneously
	BatchPredict(ctx context.Context, in *BatchPredictRequest, opts ...grpc.CallOption) (*BatchPredictResponse, error)
	// GetModelInfo returns information about the loaded model
	GetModelInfo(ctx context.Context, in *ModelInfoRequest, opts ...grpc.CallOption) (*ModelInfoResponse, error)
}

type neuralServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewNeuralServiceClient(cc grpc.ClientConnInterface) NeuralServiceClient {
	return &neuralServiceClient{cc}
}

func (c *neuralServiceClient) Predict(ctx context.Context, in *PredictRequest, opts ...grpc.CallOption) (*PredictResponse, error) {
	out := new(PredictResponse)
	err := c.cc.Invoke(ctx, NeuralService_Predict_FullMethodName, in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *neuralServiceClient) BatchPredict(ctx context.Context, in *BatchPredictRequest, opts ...grpc.CallOption) (*BatchPredictResponse, error) {
	out := new(BatchPredictResponse)
	err := c.cc.Invoke(ctx, NeuralService_BatchPredict_FullMethodName, in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *neuralServiceClient) GetModelInfo(ctx context.Context, in *ModelInfoRequest, opts ...grpc.CallOption) (*ModelInfoResponse, error) {
	out := new(ModelInfoResponse)
	err := c.cc.Invoke(ctx, NeuralService_GetModelInfo_FullMethodName, in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// NeuralServiceServer is the server API for NeuralService service.
// All implementations must embed UnimplementedNeuralServiceServer
// for forward compatibility
type NeuralServiceServer interface {
	// Predict runs model inference on a single input
	Predict(context.Context, *PredictRequest) (*PredictResponse, error)
	// BatchPredict runs model inference on multiple inputs simultaneously
	BatchPredict(context.Context, *BatchPredictRequest) (*BatchPredictResponse, error)
	// GetModelInfo returns information about the loaded model
	GetModelInfo(context.Context, *ModelInfoRequest) (*ModelInfoResponse, error)
	mustEmbedUnimplementedNeuralServiceServer()
}

// UnimplementedNeuralServiceServer must be embedded to have forward compatible implementations.
type UnimplementedNeuralServiceServer struct {
}

func (UnimplementedNeuralServiceServer) Predict(context.Context, *PredictRequest) (*PredictResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Predict not implemented")
}
func (UnimplementedNeuralServiceServer) BatchPredict(context.Context, *BatchPredictRequest) (*BatchPredictResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method BatchPredict not implemented")
}
func (UnimplementedNeuralServiceServer) GetModelInfo(context.Context, *ModelInfoRequest) (*ModelInfoResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method GetModelInfo not implemented")
}
func (UnimplementedNeuralServiceServer) mustEmbedUnimplementedNeuralServiceServer() {}

// UnsafeNeuralServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to NeuralServiceServer will
// result in compilation errors.
type UnsafeNeuralServiceServer interface {
	mustEmbedUnimplementedNeuralServiceServer()
}

func RegisterNeuralServiceServer(s grpc.ServiceRegistrar, srv NeuralServiceServer) {
	s.RegisterService(&NeuralService_ServiceDesc, srv)
}

func _NeuralService_Predict_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(PredictRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(NeuralServiceServer).Predict(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: NeuralService_Predict_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(NeuralServiceServer).Predict(ctx, req.(*PredictRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _NeuralService_BatchPredict_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(BatchPredictRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(NeuralServiceServer).BatchPredict(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: NeuralService_BatchPredict_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(NeuralServiceServer).BatchPredict(ctx, req.(*BatchPredictRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _NeuralService_GetModelInfo_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ModelInfoRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(NeuralServiceServer).GetModelInfo(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: NeuralService_GetModelInfo_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(NeuralServiceServer).GetModelInfo(ctx, req.(*ModelInfoRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// NeuralService_ServiceDesc is the grpc.ServiceDesc for NeuralService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var NeuralService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "neural.NeuralService",
	HandlerType: (*NeuralServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Predict",
			Handler:    _NeuralService_Predict_Handler,
		},
		{
			MethodName: "BatchPredict",
			Handler:    _NeuralService_BatchPredict_Handler,
		},
		{
			MethodName: "GetModelInfo",
			Handler:    _NeuralService_GetModelInfo_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "proto/neural_service.proto",
}
